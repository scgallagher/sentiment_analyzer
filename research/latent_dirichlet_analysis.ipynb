{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]\n",
    "\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data structures for various counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times each topic is assigned to each document\n",
    "document_topic_counts = [Counter() for _ in documents]\n",
    "\n",
    "# Number of times each word is assigned to each topic\n",
    "topic_word_counts = [Counter() for _ in range(K)]\n",
    "\n",
    "# Total number of words assigned to each topic\n",
    "topic_counts = [0 for _ in range(K)]\n",
    "\n",
    "# Total number of words in each document\n",
    "document_lengths = [len(d) for d in documents]\n",
    "\n",
    "# Number of distinct words\n",
    "distinct_words = set(word for document in documents for word in document)\n",
    "W = len(distinct_words)\n",
    "\n",
    "# Number of documents\n",
    "D = len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the conditional probability functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_topic_given_document(topic, document, alpha=0.1):\n",
    "    return ((document_topic_counts[document][topic] + alpha) / \n",
    "            (document_lengths[document] + K * alpha))\n",
    "\n",
    "def probability_word_given_topic(word, topic, beta=0.1):\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "           (topic_counts[topic] + W * beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for calculating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from(weights):\n",
    "    # returns i with probability weights[i] / sum(weights)\n",
    "    \n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random()\n",
    "    for i, weight in enumerate(weights):\n",
    "        rnd -= weight\n",
    "        if rnd <=0:\n",
    "            return i\n",
    "\n",
    "def topic_weight(document, word, topic):\n",
    "    return probability_word_given_topic(word, topic) * probability_topic_given_document(topic, document)\n",
    "\n",
    "def choose_new_topic(document, word):\n",
    "    return sample_from([topic_weight(document, word, topic) for topic in range(K)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = [[random.randrange(K) for word in document] for document in documents]\n",
    "\n",
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d], document_topics[d])):\n",
    "            # Remove current word/topic from the counts so they don't influence weights\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "            \n",
    "            # Choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "            \n",
    "            # Add word/topic back to the counts\n",
    "            document_topic_counts[d][topic] += 1\n",
    "            topic_word_counts[topic][word] += 1\n",
    "            topic_counts[topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print top five words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 scikit-learn 2\n",
      "0 pandas 2\n",
      "0 HBase 1\n",
      "0 R 1\n",
      "0 regression 1\n",
      "1 neural networks 2\n",
      "1 deep learning 2\n",
      "1 Cassandra 1\n",
      "1 HBase 1\n",
      "1 Python 1\n",
      "2 Java 2\n",
      "2 Python 2\n",
      "2 regression 2\n",
      "2 R 2\n",
      "2 Cassandra 1\n",
      "3 Big Data 2\n",
      "3 probability 2\n",
      "3 Hadoop 1\n",
      "3 Spark 1\n",
      "3 Storm 1\n"
     ]
    }
   ],
   "source": [
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for word, count in word_counts.most_common(5):\n",
    "        if count > 0:\n",
    "            print(k, word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "\t Machine Learning 4\n",
      "\t Databases 2\n",
      "\t Big Data and Programming Languages 1\n",
      "\n",
      "['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres']\n",
      "\t Databases 2\n",
      "\t Python and Statistics 2\n",
      "\t Machine Learning 1\n",
      "\n",
      "['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas']\n",
      "\t Python and Statistics 2\n",
      "\t Big Data and Programming Languages 2\n",
      "\t Databases 2\n",
      "\n",
      "['R', 'Python', 'statistics', 'regression', 'probability']\n",
      "\t Big Data and Programming Languages 2\n",
      "\t Databases 2\n",
      "\t Machine Learning 1\n",
      "\n",
      "['machine learning', 'regression', 'decision trees', 'libsvm']\n",
      "\t Machine Learning 2\n",
      "\t Databases 1\n",
      "\t Python and Statistics 1\n",
      "\n",
      "['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages']\n",
      "\t Big Data and Programming Languages 3\n",
      "\t Machine Learning 2\n",
      "\t Databases 1\n",
      "\n",
      "['statistics', 'probability', 'mathematics', 'theory']\n",
      "\t Big Data and Programming Languages 1\n",
      "\t Machine Learning 1\n",
      "\t Databases 1\n",
      "\t Python and Statistics 1\n",
      "\n",
      "['machine learning', 'scikit-learn', 'Mahout', 'neural networks']\n",
      "\t Python and Statistics 2\n",
      "\t Databases 1\n",
      "\t Big Data and Programming Languages 1\n",
      "\n",
      "['neural networks', 'deep learning', 'Big Data', 'artificial intelligence']\n",
      "\t Python and Statistics 2\n",
      "\t Machine Learning 1\n",
      "\t Big Data and Programming Languages 1\n",
      "\n",
      "['Hadoop', 'Java', 'MapReduce', 'Big Data']\n",
      "\t Big Data and Programming Languages 2\n",
      "\t Databases 1\n",
      "\t Machine Learning 1\n",
      "\n",
      "['statistics', 'R', 'statsmodels']\n",
      "\t Databases 2\n",
      "\t Big Data and Programming Languages 1\n",
      "\n",
      "['C++', 'deep learning', 'artificial intelligence', 'probability']\n",
      "\t Databases 2\n",
      "\t Python and Statistics 1\n",
      "\t Machine Learning 1\n",
      "\n",
      "['pandas', 'R', 'Python']\n",
      "\t Big Data and Programming Languages 1\n",
      "\t Machine Learning 1\n",
      "\t Databases 1\n",
      "\n",
      "['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB']\n",
      "\t Python and Statistics 4\n",
      "\t Databases 1\n",
      "\n",
      "['libsvm', 'regression', 'support vector machines']\n",
      "\t Big Data and Programming Languages 1\n",
      "\t Databases 1\n",
      "\t Machine Learning 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_names = ['Big Data and Programming Languages', 'Python and Statistics', 'Databases', 'Machine Learning']\n",
    "\n",
    "for document, topic_counts in zip(documents, document_topic_counts):\n",
    "    print(document)\n",
    "    for topic, count in topic_counts.most_common(5):\n",
    "        if count > 0:\n",
    "            print('\\t', topic_names[topic], count)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
